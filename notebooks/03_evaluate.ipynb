{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "###"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Muffin vs Chihuahua · Tome III · Evaluation & Inference",
   "id": "6479ade9590442f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Chapter I · Model Loading",
   "id": "50937c4143a71e73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import yaml, torch, matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from pathlib import Path"
   ],
   "id": "97ab2ccfd33aa6a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open('../config/config.yaml') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "test_dir = Path(cfg['data']['path']) / 'test'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "test_ds = datasets.ImageFolder(test_dir, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.resnet18(weights=None)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 2)\n",
    "model.load_state_dict(torch.load('../assets/muffin_vs_chihuahua.pth', map_location=device))\n",
    "model = model.to(device); model.eval()"
   ],
   "id": "efbde7a4d1f5073f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Chapter II · Accuracy & Confusion Matrix",
   "id": "50b7142300e8c351"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        out = model(x)\n",
    "        preds = torch.argmax(out, dim=1).cpu()\n",
    "        y_true.extend(y.numpy())\n",
    "        y_pred.extend(preds.numpy())\n",
    "\n",
    "acc = (np.array(y_true) == np.array(y_pred)).mean()\n",
    "print(f\"Test accuracy: {acc:.2%}\")\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=test_ds.classes)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.show()"
   ],
   "id": "8ba8ce8698b5aa59"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Chapter III · Solo Image Inference",
   "id": "ed1ecd1019731ad4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from PIL import Image\n",
    "\n",
    "def predict(path):\n",
    "    img = Image.open(path).convert('RGB')\n",
    "    img_t = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(img_t)\n",
    "        pred = torch.argmax(out, dim=1).item()\n",
    "    return test_ds.classes[pred]\n",
    "\n",
    "print(predict('../assets/images/sample_muffin.jpg'))"
   ],
   "id": "e04830ae789f9931"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
